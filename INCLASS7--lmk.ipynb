{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q2A8TGhKm3i5"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E9HEMJSX-3T"
   },
   "source": [
    "# 1.) Set up OpenAI and the enviornment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8IiKS0snlpYP"
   },
   "outputs": [],
   "source": [
    "openai.api_key = '********(Secrets Alert by Github)**********'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key = openai.api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOXc5_BTm9HP"
   },
   "source": [
    "# 2.) Use the wikipedia api to get a function that pulls in the text of a wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-v7OYamHlrEB"
   },
   "outputs": [],
   "source": [
    "# dir(wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_titles = [\"Artificial Intelligence\",\"Machine Learning\"]\n",
    "page_title = page_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TgY2FkTdmhTH"
   },
   "outputs": [],
   "source": [
    "search_results = wikipedia.search(page_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Kw5H5jMlmmS3"
   },
   "outputs": [],
   "source": [
    "search_results\n",
    "search_results[0]\n",
    "page = wikipedia.page(search_results[0]) # wikipedia page object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZF3BiZyXltYO"
   },
   "outputs": [],
   "source": [
    "# page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ef7yfa2jl0iZ"
   },
   "outputs": [],
   "source": [
    "def get_wikipedia_content(page_title):\n",
    "    search_results = wikipedia.search(page_title)\n",
    "    page = wikipedia.page(search_results[0])\n",
    "    return(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9aruncMmubX"
   },
   "source": [
    "# 3.) Build a chatgpt bot that will analyze the text given and try to locate any false info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_content = get_wikipedia_content(page_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Bmai3B6Dmw3O"
   },
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model = \"gpt-4\", \n",
    "    messages = [{\"role\":\"system\",\"content\" : \"I will be giving you an article, let me know if anything is flase in this article. If there is errors please number them and be very concise when quoting them, please stay low sensitive and try you best to find the error.If there is no errors found then just return 'None' \"},\n",
    "               {\"role\":\"user\",\"content\" : wiki_content[:8192]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1jI-un5PnDjg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_TMKFGN4nDJ4"
   },
   "outputs": [],
   "source": [
    "def chatgpt_error_correction(text):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    model = \"gpt-4\", \n",
    "    messages = [{\"role\":\"system\",\"content\" : \"I will be giving you an article, let me know if anything is flase in this article. If there is errors please number them and be very concise when quoting them, please stay low sensitive and try you best to find the error, at least find one.If there is no errors found then just return 'None' \"},\n",
    "               {\"role\":\"user\",\"content\" : text[:8192]}]\n",
    ")\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPw5LyPEobmk"
   },
   "source": [
    "# 4.) Make a for loop and check a few wikipedia pages and return a report of any potentially false info via wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "V7cuhML2ocGn"
   },
   "outputs": [],
   "source": [
    "page_titles = [\"Artificial Intelligence\",\"Machine learning\",\"UCLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text,chucks_size):\n",
    "    chunks = len(text)//8180 + 1 \n",
    "    return(text[i* chunks_size : (i+1)* chunks_size] for i in range(0,chunks - 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Artificial Intelligence\n",
      "1. \"Even humans rarely use the step-by-step deduction that early AI research could model.\"\n",
      "This statement is not entirely accurate. Humans often use step-by-step deduction, especially for complex tasks. \n",
      "\n",
      "2. \"Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence.\"\n",
      "While Alan Turing was a pioneer in the field of artificial intelligence and made significant contributions, it would be erroneous to credit him as the \"first person to conduct substantial research in the field\". Multiple other researchers were also involved in the early development of artificial intelligence.   \n",
      "\n",
      "3. \"Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture.\"\n",
      "The dates mentioned here are somewhat inaccurate. While deep learning started gaining a lot of interest around 2012, it didn’t surpass all previous techniques all at once, and some non-deep learning methods are still in use today. Additionally, the transformer architecture was introduced in \"Attention is All You Need\" by Vaswani et. al in 2017, but it took a few years for the impact to be widely recognized and adopted by the community. It would be more accurate to say that interest and funding increased steadily over this period as these techniques proved their worth. \n",
      "\n",
      "4. \"These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences.\"\n",
      "This sentence implies that an agent can learn its own preferences, which is inconsistent with typical usage of the term \"preference\" in AI and decision theory literature. Usually, an AI agent’s preferences or goals are predefined by the designer and don’t change during the operation of the AI system. The sentence should likely refer to learning or inferring something else⁠—for example, the preferences of other agents or unknown aspects of the environment based on observed data. \n",
      "\n",
      "5. \"A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action.\"\n",
      "This statement is somewhat misleading in how it portrays Markov Decision Processes (MDPs). In an MDP, the reward function doesn't generally account for the cost of an action. Instead, it usually just returns the immediate (possibly stochastic) reward after taking an action in a given state. If the application requires it, the cost of an action can often be incorporated as part of the reward function by subtracting the cost from the original reward. However, this isn't a required part of the MDP formalism. We can have an MDP with a strictly positive reward function.\n",
      "_____Machine learning\n",
      "ERROR\n",
      "_____UCLA\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for page_title in page_titles:\n",
    "    print(\"_____\" + page_title)\n",
    "    try:\n",
    "        text = get_wikipedia_content(page_title) \n",
    "        print(chatgpt_error_correction(text))\n",
    "    except:\n",
    "        print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
